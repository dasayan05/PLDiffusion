# lightning.pytorch==2.1.3
seed_everything: null

trainer:
  accelerator: gpu
  strategy: ddp
  devices: -1
  num_nodes: 1
  precision: 16-mixed
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: ./logs
      name: test
  fast_dev_run: false
  max_epochs: 3000
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 10
  num_sanity_val_steps: 0
  log_every_n_steps: 10
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
  accumulate_grad_batches: 1
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: null
  benchmark: true
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null

model:
  network:
    class_path: core.models.UNet2DModel
    init_args:
      sample_size: null
      in_channels: 3
      out_channels: 3
      center_input_sample: false
      time_embedding_type: positional
      freq_shift: 0
      flip_sin_to_cos: true
      down_block_types:
      - DownBlock2D
      - AttnDownBlock2D
      - AttnDownBlock2D
      - AttnDownBlock2D
      up_block_types:
      - AttnUpBlock2D
      - AttnUpBlock2D
      - AttnUpBlock2D
      - UpBlock2D
      block_out_channels:
      - 224
      - 448
      - 672
      - 896
      layers_per_block: 2
      mid_block_scale_factor: 1.0
      downsample_padding: 1
      downsample_type: conv
      upsample_type: conv
      dropout: 0.0
      act_fn: silu
      attention_head_dim: 8
      norm_num_groups: 32
      attn_norm_num_groups: null
      norm_eps: 1.0e-05
      resnet_time_scale_shift: default
      add_attention: true
      class_embed_type: null
      num_class_embeds: null
      num_train_timesteps: null

  training:
    scheduler:
      class_path: core.schedulers.DDPMScheduler
      init_args:
        num_train_timesteps: 1000
        beta_start: 0.0001
        beta_end: 0.02
        beta_schedule: linear
        trained_betas: null
        variance_type: fixed_small
        clip_sample: true
        prediction_type: epsilon
        thresholding: false
        dynamic_thresholding_ratio: 0.995
        clip_sample_range: 1.0
        sample_max_value: 1.0
        timestep_spacing: leading
        steps_offset: 0
        rescale_betas_zero_snr: false
    ema_decay: 0.9999
    batch_size: ${data.batch_size}

  inference:
    scheduler: null
    num_samples: 1024
    pipeline_kwargs:
      batch_size: 256
      num_inference_steps: 1000

data:
  data_dir: cifar10
  batch_size: 128
  image_resolution: 32
  HF_DATASET_IMAGE_KEY: img

ckpt_path: null
